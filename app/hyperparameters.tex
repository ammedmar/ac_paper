% !TEX root = ../ac_paper.tex

\section{Hyperparameters}\label{app:hyperparameters}

Here we discuss the hyperparameters used to train the Proximal Policy Optimization (PPO) and Transformer models of \autoref{sec:rl} and \autoref{sec:lm} respectively.
The hyperparameters of PPO are given in \autoref{tab:ppo_hyperparameters}. These hyperparameters were defined in the main text in \autoref{sec:ppo}. Each of the two networks ---the actor and the critic--- was a 2-layer feed forward neural network with 512 neurons and $tanh$ non-linearlities. We used Adam optimizer for training.


The performance of PPO is known to be highly sensitive to various implementation details in addition to the choice of hyperparameters \cite{shengyi2022the37implementation, engstrom2020implementation}. We used the single-file implementation of PPO in CleanRL \cite{huang2022cleanrl}, which has been well-benchmarked against the results of the original paper \cite{schulman2017proximal}. Following \cite{engstrom2020implementation}, we used advantage normalization and clipped value loss. If the KL divergence between the old and the updated policy exceeded the target KL divergence in a mini-batch, we skipped the remaining mini-batches in the optimization phase to avoid a large jump in policy.
We did not ablate all of the choices of hyperparameters to investigate the importance of each choice.

\begin{table}[ht]
	\centering
	\begin{tabular}{lc}
		\hline
		Hyperparameter & Value \\
		\hline
		Horizon $(T)$ & 200 \\
		Rollout Length $(T')$ & 200 \\
		Number of parallel actors & 28 \\
		Total Number of Rollouts & $\sim 2 \times 10^5$ \\
		Maximum Learning Rate & $1.0 \times 10^{-4}$ \\
		Minimum Learning Rate & 0 \\
		Learning Rate Schedule & Linear Decay \\
		Number of epochs & 1 \\
		Number of mini-batches & 4 \\
		Optimization mini-batch size & 1400 \\
		Discount ($\gamma$) & 0.999 \\
		GAE parameter ($\lambda$) & 0.95 \\
		Clipping parameter $\epsilon$ & 0.2 \\
		Value Loss coefficient, $c_1$ & 0.5 \\
		Entropy Loss coefficient, $c_2$ & 0.01 \\
		Adam epsilon parameter & $10^{-5}$ \\
		Target KL divergence & 0.01 \\
		\hline
	\end{tabular}
	\caption{Table of Hyperparameters}
	\label{tab:ppo_hyperparameters}
\end{table}

The Transformer model studied in \autoref{sec:lm} is an 8-layer transformer model with the embedding space dimension of $512$ and $4$ attention heads. The context window of the Transformer had length $1024$. We used a batch size of $12$ and constant learning rate of $6 \times 10^{-5}$. We trained for a total of $25000$ iterations. We used AdamW optimizer for training with hyperparameters $\beta_1 = 0.9$ and $\beta_2 = 0.99$. We did not use any dropout during training.