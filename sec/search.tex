% !TEX root = ../ac_paper.tex

\section{Classical Search Algorithms}\label{sec:search}

In this section, we compare the effectiveness of breadth-first and greedy search algorithms to AC-trivialize presentations in the Miller--Schupp series.
We find that the latter significantly outperforms the former.

\subsection{Breadth-first search}

We first recall the breadth-first search algorithm.
An iterative implementation of this algorithm, adapted to the problem of the Andrews--Curtis conjecture, is provided in \autoref{alg:bfs}.

We start with an initial state, which is a balanced presentation we wish to AC-trivialize, and place it in a queue.
At each iteration, a state is removed from the queue, and its neighbors are added if they have not already been visited.
This process continues until the sought-after state, i.e., a trivial balanced presentation, is found or a maximum number of states $N$ is visited. In our experiments, we set $N = 10^6$.

\begin{algorithm}
	\caption{Breadth-First Search Algorithm}\label{alg:bfs}
	\begin{algorithmic}[1] % The number [1] ensures lines are numbered
		\State \textbf{Input:} A balanced presentation $\pi$, maximum number of states to visit $N$
		\State \textbf{Output:} Boolean for whether an AC trivialization is found
		\State Initialize a queue $Q$ and enqueue the starting node $\pi$
		\State Mark $\pi$ as visited
		\While{Number of visited states is less than $N$}
		\State $u \gets Q$.dequeue() \Comment{Remove the front node of $Q$}
		\For{each neighbor $v$ of $u$}
		\If{$v$ is a trivial state}
		\State \Return True \Comment{Return True if $v$ is a trivial state}
		\EndIf
		\If{$v$ has not been visited}
		\State Mark $v$ as visited
		\State $Q$.enqueue($v$) \Comment{Add $v$ to the queue}
		\EndIf
		\EndFor
		\EndWhile
		\State \Return False \Comment{Return False if no trivial state is found}
	\end{algorithmic}
\end{algorithm}

\subsection{Greedy search}\label{ss:greedy_search}

The greedy search algorithm, described in \autoref{alg:gs}, differs only slightly from the breadth-first search algorithm in implementation.
We replace the queue with a priority queue, which stores the states in order determined by a tuple of values $(k, l)$, where $k$ is the length of the presentation and $l$ is the path length between the state and the initial state.

Instead of dequeuing the earliest state, the algorithm dequeues the state with the smallest value of $k$. If there is more than one state in the priority queue with the same value of $k$, the state with the smallest value of $l$ is chosen.

\begin{algorithm}
	\caption{Greedy Search Algorithm}\label{alg:gs}
	\begin{algorithmic}[1] % The number [1] ensures lines are numbered
		\State \textbf{Input:} A balanced presentation $\pi$ of length $k$, maximum number of states to visit $N$
		\State \textbf{Output:} Boolean for whether an AC trivialization is found
		\State Initialize a \textit{priority} queue $Q$ ordered by $(k, l)$ and enqueue the starting node $\pi$.
		$l$ is the length of the path connecting $\pi$ to the current node.
		\State Mark $\pi$ as visited
		\While{Number of visited states is less than $N$}
		\State $u \gets Q$.dequeue() \Comment{Remove the front node of $Q$}
		\For{each neighbor $v$ of $u$}
		\If{$v$ is a trivial state}
		\State \Return True \Comment{Return True if $v$ is a trivial state}
		\EndIf
		\If{$v$ has not been visited}
		\State Mark $v$ as visited
		\State $Q$.enqueue($v$) \Comment{Add $v$ to the queue}
		\EndIf
		\EndFor
		\EndWhile
		\State \Return False \Comment{Return False if no trivial state is found}
	\end{algorithmic}
\end{algorithm}

\subsection{Comparison}

We find that greedy-search algorithm outperforms the breadth-first search algorithm in the task of AC-trivializing Miller--Schupp presentations \autoref{fig:performance}.
Out of the 1190 presentations in the Miller--Schupp series with $n \leq 7$ and $\length(w) \leq 7$, greedy search solved 533 while BFS solved only 278 presentations.
Each algorithm was constrained to visit a maximum of 1 million nodes.
The percentage of presentations solved by these algorithms decreases monotonically as a function of $n$.
Remarkably, the greedy search was able to solve all presentations with $n=1$ or length less than 14.
There are, however, six presentations of length 14 that greedy search could not solve.
We verified that four of these,
\[
\angles{x, y \mid x^{-1} y^2 x = y^{3} , x = x^{-2} y^{-1} x^2 y^{\pm 1}}
\]
\[
\angles{x, y \mid x^{-1} y^3 x = y^{4} , x = y^{\pm 1} x^2 y^{\pm 1}}
\]
are AC-equivalent to $\AK(3)$, while the other two
\[
\angles{x, y \mid x^{-1} y^2 x = y^{3} , x = y x^2 y^{\pm 1} x^{-2}}
\]
could be related neither to $\AK(3)$ nor to the trivial presentation with any sequence of moves that allowed the length of each relator to increase up to 20.

For presentations solved by greedy search, we plot the maximum amount by which the length of a presentation increased in an AC trivialization path in \autoref{fig:gs_length_increase}.
In most cases, there was no increase in length; and the maximum increase was only~5.
At first glance, this seemed surprising to us, given that we allowed the relator lengths to increase by a much larger amount in our search process.\footnote{The length of each relator was allowed to increase up to \(2 \times \text{max}(2n+3, \length(w)+1) + 2\), which is twice the maximum of the initial lengths of the two relators in a presentation, plus an additional 2.
The maximum possible increase in presentation length is twice this number minus the original length.
For $n \leq 7$ and $\length(w) \leq 7$, this value lies in the range $[17, 53]$.}
However, the hard cutoff set by visiting a maximum of only 1 million nodes ensures that any presentation that needs to be mapped to a much longer presentation before it is trivialized would remain unsolved by the greedy search algorithm.
This limitation could be cured either by increasing the number of maximum nodes (at the cost of higher memory use) or by using a different criterion to order nodes in the priority queue.
It will be useful to explore the latter approach perhaps by looking for a criterion itself using deep learning algorithms.

We also plot the lengths of AC sequences discovered by greedy search as functions of $n$ and the maximum increase in the presentation length (\autoref{fig:gs_path_length}).
Unsurprisingly, path lengths increase proportionally with the increase in the length of the presentation (\autoref{fig:path_lengths_vs_length_increase}).
The following presentation with $n=5$ had the longest AC trivialization path,
\[
\angles{x, y \mid x^{-1} y^5 x = y^6,  x = y x^2 y^{-1}}
\] %correcting : \[\angles{x^{-1} y^5 x = y^6 \mid x = y x^2 y^{-1}}\]
requiring a sequence of 344 AC-moves.
Note that greedy search does not necessarily find the shortest paths of trivialization.
We will see in \autoref{sec:application} that a Reinforcement Learning algorithm finds shorter trivializing sequences for many examples of the Miller--Schupp series.
This again hints at the potential utility of exploring more efficient criteria for ordering nodes in the priority queue.

In the remainder of this paper, we will refer to the presentations from the Miller--Schupp series that were solved and unsolved by the greedy search as ``GS-solved" and ``GS-unsolved" presentations, respectively. In other words, many of our experiments will be tested on two datasets that consists of Miller--Schupp presentations with $n \leq 7$ and $\length(w) \leq 7$: the GS-solved dataset has 533 presentations, whereas GS-unsolved dataset has 657 presentations. The combined dataset that contains all presentations with $n \leq 7$ and $\length(w) \leq 7$ has size 1190.

\begin{figure}
	\centering
	\begin{subfigure}[b]{0.5\textwidth}
		\includegraphics[width=\textwidth]{fig/gs_length_increase_vs_length.pdf}
		\caption{Distribution versus initial presentation length.}
		\label{fig:gs_length_increase_vs_length}
	\end{subfigure}%
	%add desired spacing between images, e. g. ~, \quad, \qquad etc.
	%(or a blank line to force the subfigure onto a new line)
	\begin{subfigure}[b]{0.5\textwidth}
		\centering
		\includegraphics[width=1.1\textwidth]{fig/gs_length_increase_vs_n.pdf}
		\caption{Distribution versus $n$.}
		\label{fig:gs_length_increase_vs_n}
	\end{subfigure}
	\caption{The maximum increase in the length of a presentation relative to its initial length along the AC trivialization path. The increase is plotted as a function of the initial length of the presentation on the left and as a function of $n$ on the right.} \label{fig:gs_length_increase}
\end{figure}

\begin{figure}
	\centering
	\begin{subfigure}[b]{0.4\textwidth}
		\includegraphics[width=\textwidth]{fig/path_lengths_vs_length_increase.pdf}
		\caption{Distribution versus maximum increase in presentation length.}
		\label{fig:path_lengths_vs_length_increase}
	\end{subfigure}
	\begin{subfigure}[b]{0.4\textwidth}
		\centering
		\includegraphics[width=1.1\textwidth]{fig/gs_path_lengths.pdf}
		\caption{Distribution versus $n$.}
		\label{fig:gs_path_lengths}
	\end{subfigure}%
	\caption{Distribution of lengths of AC-trivialization paths learned by greedy search as a function of maximum increase in presentation length (left) and $n$ (right).} \label{fig:gs_path_length}
\end{figure}

\input{sec/n+11}

\subsection{Limitations and extensions}

While the greedy search algorithm performs better than the breadth-first search, it has some of the same limitations.
Namely, it is memory inefficient, and we cannot leverage the parallelizability of modern hardware architectures.
It also does not learn a general algorithm that would find an AC trivialization for any given balanced presentation.

Reinforcement learning algorithms, particularly policy gradient algorithms, present a promising alternative that avoids these downsides.
These algorithms are memory efficient and can be trained in a highly distributed manner, which we will focus on in the next section.

Another interesting direction to pursue involves changing the sorting function used by greedy search. Consider the family of greedy search algorithms where the priority queue is sorted by a fixed function $f: (r_1, r_2) \to \mathbb{R}$ which takes a presentation and output a real number\footnote{We can also reinterpret breadth-first search in this manner if we given as input to $f$ the path length $l$ and have the function just return $l$. From this framing it becomes clear that, whenever breadth-first search succeeds, it find a path of minimal length.}. The greedy search algorithm used here is precisely the one coming from the function $f(r_1, r_2) \to |r_1| + |r_2|$. An interesting option would be to use machine learning to try and learn a good function $f$. This approach is similar to the approach which has achieved impressive results in board games with large state spaces such as Chess and Go.