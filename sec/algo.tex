\section{The Cure: New Algorithms}\label{sec:algo}

In previous sections we explained from a variety of different perspectives that the Andrews-Curtis conjecture is a good example of a mathematical problem where the length of a solution can be much greater than the length of the initial presentation, in some cases with purely analytical lower bounds that are hyperexponential in the size of the input. In particular, we saw that small increases in presentation length under 20 quickly lead to solution lengths in the range of hundreds and higher, quickly exceeding the number of moves in the longest game of chess.

If solving a mathematical problem required finding a path of length $N$, say with $N=10^6$, an RL agent would be pretty much out of luck under typical circumstances, such as the exponential growth of the number of possible paths with their lengths, etc. The good news is that in mathematics --- and in many other domains --- such hard search problems never come in isolation. Rather, there is a distribution of problems such that generic ones are ``easy'' and a small fraction is ``hard.'' Learning this distribution for smaller values of $N$ contains the crucial information for solving new cases at the next increment of $N$.





\subsection{Supermoves}

One promising approach to making progress on the AC conjecture is to discover compositions of elementary AC moves that can explore the search space more efficiently. A classical example of such ``super-moves" are the ``elementary M-transformations" \cite{BurnsI, BurnsII}. These transformations trivialize $\AK(2)$ in just two steps, even though it is known to admit the shortest AC trivialization path of length 14.

However, a downside of elementary M-transformations is that they are infinite in number, which complicates their application in classical search techniques. We briefly explored the idea of finding AC super-moves by selecting some frequently occurring subsequences of AC moves in the paths discovered by Proximal Policy Optimization (PPO). By extending the action space $A$ of the Markov Decision Process (MDP) with these subsequences and checking whether this enhanced action space helps our agent discover shorter paths of trivialization, we noticed no significant improvements with our preliminary experiments. However, we believe this approach should be explored further.

\subsection{New algorithms}